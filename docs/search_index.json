[
["index.html", "Advanced Survey Data Analysis &amp; Survey Experiments Chapter 1 Introduction 1.1 About this Course 1.2 Software", " Advanced Survey Data Analysis &amp; Survey Experiments Brian F. Schaffner 2018-02-23 Chapter 1 Introduction 1.1 About this Course This course will focus on various aspects of advanced survey design and analysis, with a particular focus at the end of the course on survey experiments. Most of our assignments and examples will utilize data from the Cooperative Congressional Election Study, a large-scale survey of Americans that has been conducted annually since 2005. I have been a co-PI on this survey project since 2010. I am also the Director (and founder) of UMass Poll, a survey organization housed at the University of Massachusetts Amherst. This course will focus heavily on “engaged” activities to help you learn approaches and techniques. For each topic, there will be an assignment that is designed to be completed in class. While most of these projects will involve analyzing existing survey data, the course will culminate with the design, implementation, and analysis of a survey experiment designed by the students in the course. I also encourage you to bring your own survey data that you wish to analyze and I can offer help with those analyses during our time in the lab. For each class meeting, I have listed some recommended background readings. I would stronlgy encourage you to do this reading before each class. Most of these readings should be easily available on-line. However, book chapters are included at the end of this packet for your convenience. 1.2 Software This packet and the course instruction will primarily make use of the Stata statistical software. However, there is a parallel packet available for R users that I will make available in PDF form and which can also be found online here. "],
["background-on-survey-design-analysis.html", "Chapter 2 Background on Survey Design &amp; Analysis 2.1 Background Readings 2.2 Analysis Refresher – Logit 2.3 Ordinal Logit / Probit 2.4 Multinomial Logit", " Chapter 2 Background on Survey Design &amp; Analysis 2.1 Background Readings Krosnick, Jon A. “Survey Research.”&quot; Annual Review of Psychology 50.1 (1999): 537-567. Berinsky, Adam. “Measuring Public Opinion with Surveys.”&quot; Annual Review of Political Science 20 (2017): 309-29. 2.2 Analysis Refresher – Logit Open the 2008 Cooperative Congressional Election Study dataset from my website and recode some of the variables so that they will be appropriately coded: use http://people.umass.edu/schaffne/cces08.dta recode cc316c 2=0 3=., gen(stemcell) recode cc307 2=-1 3=0 4/5=., gen(pid) recode v243 6=., gen(ideology) ren v213 education The logit command in Stata works similarly to the regress command. You begin your line with logit and then list the dependent variable followed by your independent variables. An alternative to logit is probit, which works similarly, but assumes a different variance. logit stemcell pid ideology education It is important to keep in mind that the coefficients are not easily interpreted in the way that OLS coefficients are. You can ask Stata to give you odds ratios instead of coefficients by adding or to the end of your logit command. logit stemcell pid ideology education, or You can interpret the odds ratios a bit more easily. For example, you could interpret the odds ratio on education to mean that for each additional unit increase on the scale education, an individual’s odds of supporting stem cell research are 1.16 times greater. Or, perhaps slightly more intuitively, for each additional education category, an individual’s odds of supporting stem cell research increase by 16%. When you ask for odds ratios you don’t get an intercept, since the intercept doesn’t have an odds ratio. Now, let’s return to interpreting those coefficients. While odds ratios are fairly easy to calculate, they probably aren’t the best way to talk about the effects of the coefficients. More ideal and easy to understand are predicted probabilities. You can generate and plot these using the margins and marginsplot commands. First, margins will return a list of predicted probabilities under different conditions that you can specify. For example, if you wanted to know the probability that an individual who is “very liberal”&quot; on the ideology measure and average on the other covariates would support funding for stem cell research you could use this command: margins, at(ideology=1) atmeans Note that there is a .98 probability that this individual would support funding for stem cell research. Also note that the command gives you a 95% confidence interval for that prediction. Now what if you want to plot the predicted probabilities across all values of ideology? To do this, you first need to ask for those probabilities using the margins command. Then you can follow that up with the marginsplot command to graph them. margins, at(ideology=(1(1)5)) atmeans Note that the command above asks for predictions of support for stem cell research at every value between 1 and 5 in 1 point increments (this is the clause ideology=(1(1)5)). Now, you can use the marginsplot command to plot these predicted probabilities… marginsplot And now if we want to clean this graph up a bit, we can do that by adding some options to re-name the axis and graph titles: marginsplot, ytitle(&quot;Prob. of supporting funding for stem cell research&quot;) xtitle(&quot;Ideology&quot;) title(&quot;Effect of Ideology on Stem Cell Support&quot;) 2.3 Ordinal Logit / Probit An ordinal logit model is used when you have a dependent variable that takes on more than two categories and those categories are ordered. For example, Likert scales, common in survey research, are an example of ordered dependent variables. The command to estimate an ordinal logit model in Stata is ologit. In the 2008 CCES dataset, there is a question asking respondents their views on Affirmative Action policies (cc313). Respondents can indicate their support for such policies on a four point scale, ranging from 1 (“Strongly support”“) to 4 (”Strongly oppose“”). One could collapse these categories into “support”&quot; or “oppose,”&quot; but why throw away detail about the strength of support? To estimate an ordinal logit model on this question, you could use the following command: ologit cc313 ideology pid education The coefficients in this output are estimating the effect of a one unit increase in each independent variable on the log odds of moving to a higher category on the scale of the dependent variable. These can be converted to odds ratios using the same or option noted above. Predicted probablities can be created using the marginsplot command. Following the process outlined below for mlogit will work with ologit as well (to create predicted probabilities for each outcome category). 2.4 Multinomial Logit For cases when the dependent variable has unordered categories, we use multinomial logit. In Stata, you would use the mlogit command to implement this type of model. Let’s use variable cc309 as our dependent variable. That variable asks respondents what they would most want to do to balance the federal budget – cut defense spending (1), cut domestic spending (2), or raise taxes (3). Let’s use the same set of independent variables. mlogit cc309 ideology pid education Each coefficient and statistical test above is calculated in relation to the base category (cut domestic spending). So, the coefficients are telling you whether a coefficient means there is a significant difference between the odds of choosing the category relative to the base category, but not whether there is a significant difference across other categories. As with the logit model, you can again create predicted probabilities and plots to help look at the size of the effects. margins, at(ideology=(1(1)5)) atmeans marginsplot, ytitle(&quot;Probability&quot;&quot;) xtitle(&quot;Ideology&quot;&quot;) Let’s clean this up a bit to make things clearer. In particular, let’s label the legend better by adding an option to label each key in the legend. I’m also going to get rid of the title by specifying a blank title: marginsplot, ytitle(&quot;Probability&quot;&quot;) xtitle(&quot;Ideology&quot;) title(&quot;&quot;) legend(order(1 &quot;Cut defense&quot;&quot; 2 &quot;Cut domestic&quot;&quot; 3 &quot;Raise taxes&quot;&quot;)) The graphic shows that most of the effect of ideology occurs in choosing between the “cut defense” and “cut domestic” categories. Almost everyone, regardless of ideology, prefers to not raise taxes. "],
["approaches-to-sampling.html", "Chapter 3 Approaches to Sampling 3.1 Background Readings 3.2 Sampling in Stata", " Chapter 3 Approaches to Sampling 3.1 Background Readings Lohr, Sharon. Sampling: Design and Analysis. Chapter 1. Frankel, Martin R., and Lester R. Frankel. ``Fifty years of survey sampling in the United States.&quot; Public Opinion Quarterly (1987): S127-S138. Brick, J. Michael. ``The future of survey sampling.&quot; Public Opinion Quarterly 75.5 (2011): 872-888. Baker, Reg, et al. ``Summary Report of the AAPOR Task Force on Non-probability Sampling.&quot; Journal of Survey Statistics and Methodology (2013). (And read subsequent commentary) Ansolabehere, Stephen, and Brian F. Schaffner. “Does survey mode still matter? Findings from a 2010 multi-mode comparison.” Political Analysis (2014). 3.2 Sampling in Stata One can use almost any program to draw a random sample. In Stata, you could write your own basic program to sample observations, making use of Stata’s random number generator (e.g. gen random=runiform()). However, there is also a useful packaged program that streamlines the process for you and makes it easier to do sampling proportional to size – samplepps. Let’s start by opening a dataset that is a list of most of the local communities (towns and cities) in the United States. use http://people.umass.edu/schaffne/communities.dta Now, let’s say that we wanted to use these communities to conduct a cluster sample. In essence, we want to select 100 communities (the idea is that we would then travel to those communities and randomly select households to interview). samplepps is specifically designed to conduct sampling proportional to size. In this case, we have the population of each community as one of the variables in our dataset (variable name: population). So, to take our sample of 100 communities, we could do the following: samplepps insample, ncases(100) size(population) This creates a new variable called insample which equals 1 if the observation in the dataset was selected into your sample (so there should be 100 cases with 1s). But what if you don’t want to sample proportional to the size of the community. That is, what if you want each community to have an equal chance of being selected. Well, this is easy enough; you just have to trick samplepps by giving all the cases in your dataset the same size. So you could simply do this: gen size=1 samplepps insample2, ncases(100) size(size) Now, if you want to see the impact of sampling proportional to size versus just taking a random sample where all communities have an equal chance of being selected, check out the average population size for the communities who have a 1 for insample compared to those who have a 1 for insample2. The latter communities have much smaller populations, of course. Finally, it is worth noting that you can use if commands with samplepps, and this can come in handy if you want to do stratified sampling. For example, in this dataset, some regions have many more communities than others. But you could use the if command to sample within each region (one region at a time). "],
["constructing-and-using-design-weights.html", "Chapter 4 Constructing and Using Design Weights 4.1 Background Readings 4.2 Using Weights in Stata", " Chapter 4 Constructing and Using Design Weights 4.1 Background Readings DeBell, Matthew and Jon A. Krosnick. “Computing Weights for American National Election Study Survey Data.” Kreuter, F, and Valliant, R., (2007), “A survey on survey statistics: What is done and can be done in Stata.” The Stata Journal Volume 7, Number 1, pages 1 - 21. 4.2 Using Weights in Stata In a dataset, survey weights are captured by a variable that indicates how much each respondent should “count.” For example, a respondent who has a 1 for a weight variable would count as a single respondent; a respondent who receives a .5 for a weight variable should count as half a respondent; and a respondent who has a 2 would count as two respondents. Stata has four different options for weighting statistical analyses. You can read more about these options by typing help weight into the command line in Stata. However, only two of these weights are relevant for survey data – pweight and aweight. Using aweight and pweight will result in the same point estimates. However, the pweight option is the more correct option because aweight does not calculate the standard errors correctly. However, in some cases you may be forced to use aweights as most, but not all, Stata commands support the pweight option (e.g. graphing options). The [2010 UMass Poll Massachusetts Exit Poll] (http://people.umass.edu/schaffne/mass_exitpoll.dta) includes a variable called weight. Respondents in the exit poll were weighted to account for the stratified nature of the sampling procedure. By stratifying towns by geography and other factors, not every voter had an equal chance of being sampled. Thus, the weight variable adjusts for this fact. The easiest way to implement sampling weights when conducting statistical analysis is a two-step process. First, just one time at the beginning of your session you need to tell Stata that your dataset includes a weight variable by typing the following command: svyset [pw=weight] svyset is the command, then the rest of the command is in brackets. pw is the type of weight being used (it should always be pw for survey data) and weight is the name of the variable that includes the information needed to weight the data. Once you have done this, Stata now knows which variable to use to weight the data (and how to apply those weights). However, you still have to ask Stata to weight the data whenever you run an analysis. For example, let’s say we wanted to look at the vote for Governor. If we just tabulated the variable, we would get the following: However, the above tabulation does not weight the data to adjust for the sampling approach. To do this, you need to use svy: as a prefix to whatever command you are trying to use. So, now you can do the same tabulation but apply the weights to it: Notice that applying the weights had a pretty big effect on the results. With the sampling weight accounted for, Patrick receives 52% of the vote, much closer to what he actually received in the election. "],
["constructing-and-using-post-stratification-weights.html", "Chapter 5 Constructing and Using Post-Stratification Weights 5.1 Creating Post-Stratification Weights in Stata", " Chapter 5 Constructing and Using Post-Stratification Weights 5.1 Creating Post-Stratification Weights in Stata If you know the population values of demographics that you wish to weight on, you can create the weights yourself using an approach known as post-stratification raking. There is a user-written program in Stata to allow for the creation of such weights. The function is called ipfweight. As an example, we will use the [2014 Massachusetts Exit Poll data] (http://people.umass.edu/schaffne/mass\\_exitpoll\\_2014.dta). The dataset already has a sampling weight included, to adjust for the stratified cluster sample approach taken. However, because of unequal response rates among different demographic groups, we also need to do additional post-stratification weighting. Here is what we know about the demographic composition of the electorate in 2014 according to voting records: Characteristic % of Electorate Female 53% White 88% Black 4% Hispanic 5% Age 18-29 7% Age 65 and older 30% We can use this information to produce post-stratification weights for the survey. First, the easiest thing to do is create indicator variables for each category we will weight on. We can do this as follows: recode gender 2=1 1=0, gen(female) tab race, gen(racecat) ren racecat1 white ren racecat2 black ren racecat3 hispanic tab age, gen(agecat) ren agecat1 age18 29 ren agecat6 age65 over Now, we can use the ipfweight command to weight to the population values. To do this, we use the following command: ipfweight female white black hispanic age18_29 age65_over, gen(weight) val(47 53 12 88 96 4 95 5 93 7 70 30) maxit(25) st(sampleweight) This command first identifies the variables on which to weight (female, white, black, hispanic, age18_29 and age65_over). The gen() option specifies the name of the weight variable that will be created after this command is executed (I’m just calling it `weight'' here). Theval()` option is necessary. This part of the command specifies the point estimate for each category of the variables specified earlier. So, for example, the first two numbers are 47 and 53, because on the variable female, we are looking for 47% to be 0 (male) and 53% to be 1 (female). The next two numbers are 12 and 88, because we are looking for 12% to take on a 0 for the white variable (indicating non-white) and 88% to take on a value of 1 (indicating white). And so on… The st() option is used to indicating the starting weight for each observation. You will often not have a starting weight like this, but here we do because the sample is already weighted to account for the stratified cluster sample (captured by the sampleweight variable). Finally, maxit is simply the maximum number of times that Stata will go through the raking process. It probably makes sense to set this at least to 10, but you may want to set it higher when you are weighting on more variables. Once you execute this command, a new variable called weight (or whatever you named it) will appear in your dataset. For the exit poll, the weight variable has a mean of 1 (it should always have a mean of 1), a standard deviation of 1.15, and it ranges from .22 to 21.35. Often, pollsters trim their weights to ensure that no single respondent receives too much influence over the point estimates. Only 4 respondents receive a weight in excess of 8, so we might wish to trim the weights at 8, so that nobody receives a weight in excess of 8. To do this, we simply use the ,up() option in the ipfweight command, as so: ipfweight female white black hispanic age18\\_29 age65\\_over, gen(weighttrimmed) val(47 53 12 88 96 4 95 5 93 7 70 30) maxit(25) up(8) st(sampleweight) "],
["item-scaling.html", "Chapter 6 Item Scaling 6.1 Background Readings 6.2 Scaling Items in Stata 6.3 Simple Index using alpha 6.4 Index using Factor Analysis factor 6.5 Using IRT to Create a Scale", " Chapter 6 Item Scaling 6.1 Background Readings Warshaw, Christopher. 2017. “Latent Constructs in Public Opinion.” The Oxford Handbook of Polling and Polling Methods. DOI: 10.1093/oxfordhb/9780190213299.013.30 Maria Orlando Edelen and Bryce B. Reeve. 2007. “Applying item response theory (IRT) modeling to questionnaire development, evaluation, and refinement.” Quality of Life Research 16: 5 - 18. Treier, Shawn and Simon Jackman. 2008. “Democracy as a Latent Variable.” American Journal of Political Science. Vol. 52, No. 1, pp. 201-17. 6.2 Scaling Items in Stata In the 2010 CCES, respondents were asked to indicate whether they would support using U.S. troops to support each of the following objectives. The objectives were: Variable Objective cc414_1 Ensure supply of oil cc414_2 Destroy terrorist camp cc414_3 Intervene in genocide or civil war cc414_4 Assist spread of democracy cc414_5 Protect us allies under attack cc414_6 Help un uphold international law Responses are coded as either “1” if they support the use of troops in that situation and “2” if they do not. Let’s start by re-coding these so that “0” is the code for those who do not support using troops in that situation. recode cc414 1 cc414 2 cc414 3 cc414 4 cc414 5 cc414 6 (2=0) In the following sections, we examine three methods of combining these six items into a single scale measuring attitudes toward immigration policy. 6.3 Simple Index using alpha We want to see whether the variables are measuring the same concept. We could do this either by creating a simple index with the alpha command or by creating the index using factor analysis. To create the index using alpha, we would use the following command: alpha cc414 1 cc414 2 cc414 3 cc414 4 cc414 5 cc414 6, gen(intervention) The alpha command has Stata indicate the reliability for a set of measures; that is, it indicates the extent to which the variables are measuring the same concept. In this case, our items receive a reliability value of .58, which is not particularly high. We added an option to the command: gen() tells Stata to combine the measures into a single measure that is simply the average value of the other variables. We can think of this variable as the underlying support for military interventions. You can see how this variable is distributed: twoway histogram intervention, percent bc(blue) This can simply be interpreted as the proportion of times that respondents supported military intervention. Note that very few supported all reasons for an intervention, and the mode was .5 (half of the situations). 6.4 Index using Factor Analysis factor Alpha essentially creates a simple addititve index. But a second way to combine these variables is through a factor analysis. Factor analysis potentially provides more information because it allows some items to have more influence over the latent (index) variable than others. To run a factor analysis use the factor command: factor cc414_1 cc414_2 cc414_3 cc414_4 cc414_5 cc414_6 There are two things to look at here. First, the Eigenvalue for the first factor is above 1, which tells us that there is some underlying latent variable that the combination of these variables are jointly measuring. Second, the factor loadings for that first factor are above .3 for all but the sixth variable. Generally, we might drop a variable from our factor analysis if its loading was less than .3 and we did not have a great theoretical reason for it to be there. But in this case we’ll go ahead and keep it in. So let’s go ahead and use the predict command to generate our new variable that combines the measures of intervention. predict intervention2 The output here gives a sense of how much each variable contributes to the value of the underlying latent variable (intervention2). Note that cc414_6 gets the least weight, which makes sense since it also had the lowest factor loading. The new variable created by this command (intervention2) is the underlying latent variable that we are assuming captures one’s general support for military interventions. The variable will be created as a standard normal variable, meaning that it’s mean will be approximately 0 and it’s standard deviation will be approximately 1. Let’s take a look at the distribution of this variable: twoway histogram intervention2, percent bc(blue) Note that the distribution of this variable looks quite a bit different from the one we just created with the alpha command. Despite this fact, the measures are fairly highly correlated (at .98). See the scatterplot below. The key difference is that the factor analysis provides a bit more gradation in the measure compared to just averaging the measures. twoway scatter intervention intervention2, aspect(1) ytitle(&quot;Alpha created measure&quot;) xtitle(&quot;Factor analysis created measure&quot;) 6.5 Using IRT to Create a Scale Item response theory (IRT) is another approach to scaling indicators, with its foundations coming from research on testing. Unlike factor analysis, the IRT approach assumes that the items are capturing a single underlying latent variable. IRT is also specifically designed for binary or categorical items. Like factor analysis, IRT allows for some variables to contribute more to determining that latent variable. Stata 14 includes a family of IRT approaches. The approach we will use here (2 parameter logit - 2pl) is designed for binary items and allows for each item to contribute differently to the construction of the underlying latent variable. To run the model, we use the following command: irt 2pl cc414_1-cc414_6 As the name of this approach implies, there are two parameters estimated for each item. The first is the discrimination parameter (a). This parameter indicates how highly correlated the item is with the underlying latent variable. For example, cc414_2 and cc414_5 both have discrimination parameters at or above 2, which indicates that those items are particularly valuable for differentiating respondents on the latent trait. These values are similar to factor loadings. The second parameter for each item is the difficulty parameter. This is essentially an intercept for each item – indicating how frequently the sample, on average, responded positively to the item. For example, the difficulty parameter for cc414_5 (using troops to protect allies who are under attack) indicates that this was the item that respondents most frequently responded “yes” to (and a simple cross tabulation of the items would confirm this). cc414_4 (using troops to assist the spread of democracy) was the item that individuals responded “yes” to least frequently. We can visualize these items with the following command: irtgraph icc This graphic shows the relationship between the latent trait (theta) and the probability of answering “yes” to each of the items. Note that most of the items have a fairly strong correlation with theta, though this is not particularly true for cc414_6 (which also did not load very highly with the others when we conducted the factor analysis); that item has a gradual slope. Now, we can turn to generating a variable that captures each individual’s value for the underlying latent trait (theta). To do this, we use the predict command with the , latent option: predict intervention3, latent And just for fun, let’s see how this compares to the latent variable created through factor analysis: These are highly correlated (at .996), so at least in this case, it would not have mattered much if you had used IRT or factor analysis. "],
["matching-and-balancing-techniques.html", "Chapter 7 Matching and Balancing Techniques 7.1 Background Readings 7.2 Two Approaches to Matching/Balancing in Stata 7.3 Coarsened Exact Matching 7.4 Entropy Balancing", " Chapter 7 Matching and Balancing Techniques 7.1 Background Readings Blackwell, Matthew, Stefano Iacus, Gary King, Giuseppe Porro. 2009. “cem: Coarsened exact matching in Stata.” Stata Journal. Vol. 4, pp. 534-546. Hainmueller, Jens and Yiqing Xi. 2013. “ebalance: A Stata Package for Entropy Balancing.” Journal of Statistical Software. Vol. 54, Issue 7. 7.2 Two Approaches to Matching/Balancing in Stata Let’s imagine that we want to know whether having children makes an individual more likely to support the Children’s Health Insurance policy (variable cc332b). We could simply do a cross-tabulation of having children and support for the policy. In a set-up like this one, we are essentially treating having a child as the treatment and one’s opinion on the insurance program is the outcome variable. svy: tab cc332b v242, col Based on this simple bivariate analysis, it appears as though inviduals who have children are about 5 points more supportive of the children’s insurance program (p&lt;.001). But, of course, having children is not randomly assigned, so there may be many ways in which those with children are different from those without them, and we would want to be sure to account for these factors when making this comparison. We would want to account for as many of those factors as possible when making this comparison. We will attempt to account for the following variables: Variable Name Description v207 Year of birth v244 Interest in news and public affairs v211 Race Of course, it is possible (and probably desirable) to match/balance on far more variables than this, but for the sake of this particular exercise, these three variables will suffice. 7.3 Coarsened Exact Matching Coarsened exact matching is a method that essentially seeks to find observations in the “control” and “treatment” groups that are close or exact matches on the variables you specify. So, in this case, we are looking to pair individuals who do and do not have children based on their year of birth, interest in news, and race. Note that you will need to install the program for this by typing: ssc install cem Then follow the links to make sure the cem module is installed on your Stata. Now, before we begin, we should work to recode the variables that we are going to use in this analysis. recode cc332b 2=0, gen(chip) recode v242 2=0, gen(kids) recode v244 7=4, gen(interest) recode v211 2/9=0, gen(white) Now, we have one interval variable (year of birth) and two categorical variables that we wish to match on. Because our sample size is so large, we can force cem to exact match on the categorical variables (white and interest). Then we will coarsen exact match on year of birth. The variable kids is our indicator of the treatment. Note that the treatment can only take on two values. If you have multiple treatments, then things become a bit more complicated. To avoid an error message, drop any cases on which you do not have a value for the treatment variable: drop if kids==. Before we do the matching, let’s take a look at just how imbalanced our control and treatment groups are. We can do this by using the imb command: imb white interest v207, treatment(kids) The main statistic to look at here is the L1 value. The L1 statistic takes on values ranging from 0 to 1, indicating the degree of imbalance on the variables specified. We will keep this value of L1 in mind to see how much we can reduce the imbalance by matching. Now go ahead and conduct the matching: cem white (#0) interest (#0) v207, treatment(kids) Note that the L1 statistic is now just .09. So we have brought it very close to 0, and far away from the the degree of imbalance we had before matching. We can also see that we were able to find a match for most cases in our data (only 184 unmatched cases). Note that L1 is smallest for the two variables on which we did exact matching (white and interest). After conducting the cem, we now have three new variables in our dataset. cem_matched is simply an indicator of which cases were matched versus unmatched. The most important variable is cem_weights. Unless you chose to do a k2k match, it will be crucial to use the weights in your analyses. However, you must use these as iweights. So, now let’s examine the effect of having kids both before matching and after matching: reg chip kids reg chip kids [iw=cem_weights] The second solution is the one that incorporates the matching, through the implementation of the weights. Note that the statistically significant difference of 5.6 points observed before matching vanishes once we do the matching. In that analysis, there is a very small and statistically indistinguishable difference between those who do and do not have kids when it comes to attitudes towards the children’s health insurance policy. The weights created by cem are to provide the most efficient use of the data possible by using as many observations as possible. However, if you have a large number of observations and wish to simplify your analysis, you can to k2k matching, which means pairs will be created so that for each individual in the control group there is just one match in the treatment group (and vice versa). To do this, simply add the k2k option after the comma in the cem command. And then, limit your subsequent analyses only to those who are identified as having a match by the cem_matched variable: cem white (#0) interest (#0) v207, treatment(kids) k2k reg chip kids if cem_matched==1 7.4 Entropy Balancing Entropy balancing is an alternative approach to producing balance between the treatment and control groups. This is done by weighting the observations to produce balance on the variables specified. If we wanted to balance the control and treatment groups using ebalance, we would type the following: ebalance kids white interest v207 Note that the treatment variable must come first, after the ebalance command. Then you include the co-variates on which you wish to balance. This produces the following output: This output confirms which variable is being used as the treatment and which variables are being used to balance. It then shows summary information about the variables in the treatment and control conditions before and after the new weights are applied. This command produces a new variable in your dataset called _webal. You can now use this variable just as you would any other weight variable. So, let’s run the analysis from above, but this time using the weights from entropy balancing: svyset [pw=_webal] svy: reg chip kids Again, the conclusion derived from this analysis is that having children has no impact on one’s attitude toward the children’s health insurance program. One final option to note about ebalance is the ability to account for the fact that your data may already be weighted to account for sampling design or response bias. The option is basew, and for the analysis above, you would specify it as so: ebalance kids white interest v207, basew(v101) Using these new entropy balancing weights changes the results only marginally: "],
["construction-and-analysis-of-panel-data.html", "Chapter 8 Construction and Analysis of Panel Data 8.1 Background Readings 8.2 Analyzing Panel Data in Stata 8.3 Reshaping Data 8.4 Simple Panel Analysis Commands", " Chapter 8 Construction and Analysis of Panel Data 8.1 Background Readings Schaffner, Brian F. and Stephen Ansolabehere. “Guide to the 2010-14 CCES Panel Study.” http://dx.doi.org/10.7910/DVN/TOE8I1 Prior, Markus. 2010. “You’ve Either Got It or You Don’t? The Stability of Political Interest over the Life Cycle.” Journal of Politics. Vol. 72, No. 3, pp. 747-766. Hillygus, D. Sunshine and Steven A. Snell. 2015. “Longitudinal Surveys: Issues and Opportunities.” 8.2 Analyzing Panel Data in Stata We will use the 2010-2014 CCES Panel Data as an example to demonstrate some panel analysis techniques. You may download the survey from here: http://dx.doi.org/10.7910/DVN/TOE8I1 8.3 Reshaping Data The CCES data comes in “wide” format. That means that each row is an individual and their responses for each year of the survey are recorded across the dataset in columns. For example, the variable CC10_308a is the individual’s approval of President Obama in 2010, CC12_308a is the approval of Obama in 2012, and CC14_308a is the value of approval for 2014. While there may be some value to having data appear in this format, it is necessary to change to “long” format in order to conduct panel analyses in Stata. Long format means that there is a separate observation for each individual in each year. Thus, what you would end up with for this panel dataset is three observations for each respondent (2010, 2012, and 2014) with one variable for each question that was asked in each of those years. In other words, instead of having CC10_308a, CC12_308a, and CC14_308a, you would want just a single CC_308a. You would then have a caseid variable that is unique to each respondent, and a year variable that indicates which year each variable applies to. Once we understand some of the re-naming conventions, it is not particulalry difficult to re-shape the dataset so that it works in this form. The do-file below shows how we would do this with the wide-form panel data. The basic gist is that we would be subsetting the wide-form dataset into three different datasets…one for each wave (or year). We then rename the variables so that they will have the same variable names in each year (e.g. CC_308a instead of CC10_308a, CC12_308a, and CC14_308a). Once you have your data set up in long form, you can tell Stata that it is in panel format. To do this, you use the xtset command and then follow that command first with the variable indicating each unique respondent and the variable indicating each time period. xtset caseid year However, in this case we want to specify to Stata that the time periods in our analysis happen every two years rather than every year. Thus, we can include an additional option to the above command to make this clear: xtset caseid year, delta(2) 8.4 Simple Panel Analysis Commands Now that we have xtset the data, we can use the entire body of xt commands in Stata. To see what these include, you can type help xt into the command line in Stata. Note that most common regression models are avaiable in xt format (e.g. xtreg, xtlogit, xtologit, and so on). Let’s say that we are interested in understanding whether people punish or reward the president for their own employment situation. In other words, we want to see whether the act of getting a job (or losing a job) affects how people evaluated President Obama during his term in office. The dependent variable we will use here is a question asking how much people approve of Obama (CC308a). Our key independent variable will be whether an individual states that they are employed full-time or unemployed (we will exclude other employment responses from this analysis). We need to do a little re-coding to get started: recode employ 4=0 2/3=. 5/9=., gen(employed) recode CC308a 1=3 2=2 3=1 4=0 5=., gen(obama_approval) The most basic way we might try to analyze this data is to take a difference-in-difference approach. Essentially, what we are attempting to discern is whether individuals whose employment situation changes from one wave to the next change their opinions of Obama at a different rate compared to those whose employment situation does not change. We can do a fairly simple first cut at this analysis through a regression framework. The first thing we need to do is created a lagged version of the employment variable (i.e. whether the person was employed in the previous wave). gen lagged_employed=l1.employed Now, let’s run a simple regression where we interact employed with lagged_employed. For our dependent variable, we want to know the difference in approval from the previous time period (because we are comparing the differences between the difference in approval for each group). Since Stata knows we have panel data, we can specify that we want the difference as our dependent variable using the d1. operator. So: reg d1.obama_approval lagged_employed#employed margins, over(lagged_employed employed) Using the margins command after the regression provides a very easy way of seeing how approval changes among each of the four groups. For example, there was a .07 point drop in approval among individuals who were unemployed in one time period and stayed unemployed in the next wave. By comparison, approval dropped .048 for those who moved from being unemployed to being employed. Given the size ot the standard errors for these means, there is no significant difference between the two groups. You can also compare people who had a job and lost it to those who had and kept a job. Again, there is no sigificant difference in approval for these groups. The difference-in-difference approach is often not the most efficient estimation of the data. This is because it only uses information comparing one time period to the period immediately before it; however, we can also learn something from comparing across multiple time periods. Additionally, the difference-in-difference approach works with binary treatment variables, but it does not easily handle variables with gradations (i.e. income, partisanship, etc.). Another approach is using panel regression with unit fixed effects. To do this in Stata, we take advantage of the xtreg command. xtreg obama_approval employed, fe The , fe options specifies a fixed effects model. Essentially, we are controlling for any time-invariant differences across individuals by taking this approach. The information being used to determine the effect of employment status on approval is only for individuals whose employment status changed at some point during the 3 waves. Based on this approach, employment status appears to be unrelated to approval for Obama (based on the coefficient for the employed variable). "],
["survey-experiments.html", "Chapter 9 Survey Experiments 9.1 Background Readings 9.2 Analyzing and Presenting Results from Survey Experiments", " Chapter 9 Survey Experiments In this section of the course we will learn about the strengths and weaknesses of survey experiments. We will then learn best practices for designing and analyzing such experiments. 9.1 Background Readings Druckman et al. 2011. Cambridge Handbook of Experimental Political Science. Chapters 2-3. Gaines, Brian J., James H. Kuklinski, and Paul J. Quirk. “The logic of the survey experiment reexamined.” Political Analysis. 15, no. 1 (2007): 1-20. Barabas, Jason, and Jennifer Jerit. “Are survey experiments externally valid?” American Political Science Review. 104, no. 02 (2010): 226-242. Berinsky, Adam J., Michele F. Margolis, and Michael W. Sances. 2014. “Separating the Shirkers from the Workers? Making Sure Respondents Pay Attention on Self-Administered Surveys.” American Journal of Political Science. Vol. 58, No. 3, pp 739-753. Albertson, Bethany and Shana Kushner Gadarian. 2016. “Did that Scare You? Tips on Creating Emotion in Experimental Subjects.” Political Analysis. Hainmueller, J., Hangartner, D., and Yamamoto, T. 2015. “Validating Vignette and Conjoint Survey Experiments Against Real-World Behavior?” Proceedings of the National Academy of Sciences. Montgomery, Jacob M., Brendan Nyhan, and Michelle Torres. 2017. “How conditioning on post-treatment variables can ruin your experiment and what to do about it.” Working Paper. http://www.dartmouth.edu/~nyhan/post-treatment-bias.pdf 9.2 Analyzing and Presenting Results from Survey Experiments The great thing about running an experiment is that analyzing the results is often pretty straightforward. I have a couple of basic “go-to” routines to present basic experimental treatment effects, which I’ll outline here. Of course, things can get increasingly complicated with experiments that have lots of conditions or other features, but this will get you started. Here is a description of the experiment we’ll analyze here. It is a brief vignette, with random assignment of whether respondents received some kind of additional information about the candidate: In Illinois, Democrat David Gill is running for a seat in the U.S. House of Representatives. Gill is an ER physician who is married and has six children with his wife Elaine. [RANDOMIZED TEXT HERE] He stated that he was running for Congress, “to revive the fading American Dream and make sure DC is setting the right priorities for our families again.” Randomized text (with equal probability): No additional text (control condition). Gill was endorsed by the National Organization for Women. Gill was endorsed by the National Organization for Women because of his pro-choice views. UMA311: Based on what you have heard, where would you place Gill on the ideological scale? Very liberal Liberal Somewhat liberal Moderate Somewhat conservative Conservative Very Conservative The data to analyze this data can be accessed here. Essentially, the idea was to see whether an endorsement from the National Organization for Women would change how liberal or conservative people thought the candidate was. So our key dependent variable is UMA311 – where respondents placed Gill on the 7-point ideological scale. And we want to see whether this varies across our three conditions (the control and 2 treatment conditions). A common way that people sometimes plot these things is just to show the overall level of the dependent variable for each condition. Something like this: graph bar UMA311, over(condition) Of course, there are several problems with this particular graph. One is that we don’t have any uncertainty estimates for these figures (e.g. confidence intervals). We could recover this information by using a very basic regress command and then using marginsplot as so: reg UMA311 i.condition margins, over(condition) marginsplot, recast(bar) xlabel(, angle(45)) title(&quot; &quot;) ytitle(&quot;Conservatism&quot;) xtitle(&quot; &quot;) So this is a little better, and we could further play with this graph to clean this up. But it still isn’t as informative as we might prefer. In particular, what we really want here are the treatment effects. That is, the difference between the treatment condition(s) and the control condition. This graphic makes it so we have to figure that out for ourselves. So, a better approach would be to essentially produce a coefficient plot. There are a couple of ways to do this in Stata (including the margins command), but the easiest is to use the coefplot package. reg UMA311 i.condition coefplot, drop(_cons) xline(0) plotr(lc(none)) xlabel(-1.5 -1 -.5 0 .5) A few points here. First, I use the drop(_cons) option to omit the plotting of the intercept. That is pretty much irrelevant to understanding the treatment effects and it is confusing to have it in the same plot. I like plotting a line at 0 (xline(0)) as a reference. If a treatment effect is significant, then the confidence interval for that effect should not overlap with the zero line. That is what we see here. This also gives us a better sense of the size of the treatment effects. The endorsement with no explanation moves peoples’ estimates of Gill’s ideology a full point more liberal, whereas the endorsement with the explanation only has an effect that is about half has large. Note that I had to use the xlabel(-1.5 -1 -.5 0 .5) option so that the reference line would show up since the default range for this particular plot would not include zero otherwise. Finally, what if we want to see whether our treatment effects are heterogeneous by some other variable in our model? Well, the easiest thing to do is to estimate separate regression models and combine them into a single plot. In the code below, I estimate treatment effects for men, store the results, then for women (and store those results), and then use coefplot to bring in the results for both men and women into a single plot. reg UMA311 i.condition if gender==0 est store men reg UMA311 i.condition if gender==1 est store women coefplot men women, drop( cons) xline(0) xlabel(-1.5 -1 -.5 0 .5) "]
]
